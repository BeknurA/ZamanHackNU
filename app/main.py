"""
–ü–æ–ª–Ω—ã–π API —Ä–æ—É—Ç–µ—Ä –¥–ª—è Zaman Bank
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ API
"""

import uvicorn
import webbrowser
import httpx
import chromadb
import json
import os
from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, StreamingResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
import threading
from datetime import datetime
import random

load_dotenv()

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
API_KEY = os.getenv("API_KEY")
BASE_URL = "https://openai-hub.neuraldeep.tech"
LLM_MODEL = "gpt-4o-mini"
EMBEDDING_MODEL = "text-embedding-3-small"

# --- FastAPI ---
app = FastAPI(
    title="Zaman Bank AI Assistant API",
    description="–ü–æ–ª–Ω—ã–π API —Ä–æ—É—Ç–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö OpenAI —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory="../static"), name="static")
INDEX_HTML_PATH = "../static/index.html"
CHAT_HTML_PATH = "../static/chat.html"

USER_STATE_CACHE: Dict[str, Dict[str, Any]] = {}
http_client = httpx.AsyncClient(timeout=120.0)

# --- ChromaDB ---
try:
    db_client = chromadb.PersistentClient(path="./zaman_db")
    collection = db_client.get_collection(name="zaman_products")
    print("‚úÖ ChromaDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∞.")
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ ChromaDB: {e}")
    collection = None


# ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ====================

def load_json_safe(filepath: str, default: Any = None) -> Any:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ JSON"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filepath}: {e}")
        return default


def load_personalized_client_context() -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞"""
    data = load_json_safe("../data/zaman_personalized_rag_data.json", [])
    if not data:
        return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∏–µ–Ω—Ç–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."
    
    try:
        client_profile = next(item for item in data if item.get("id") == 0)
        details = client_profile.get("client_details", {})
        summary = client_profile.get("financial_summary_kzt", {})
        
        return (
            f"–ö–ª–∏–µ–Ω—Ç: {details.get('name')}, {details.get('age')} –ª–µ—Ç, {details.get('city')}. "
            f"–°—Ç–∞—Ç—É—Å: {details.get('status')}. "
            f"–ï–∂–µ–º–µ—Å—è—á–Ω—ã–π –¥–æ—Ö–æ–¥: {summary.get('monthly_salary_in_kzt')} KZT. "
            f"–ü–ª–∞—Ç–µ–∂–∏ –ø–æ –∑–∞–π–º–∞–º: {summary.get('loan_payment_out_avg')} KZT/–º–µ—Å."
        )
    except (StopIteration, KeyError, TypeError):
        return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∏–µ–Ω—Ç–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."


def load_benchmark_data() -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–µ–Ω—á–º–∞—Ä–∫–∏"""
    benchmarks = load_json_safe("../data/zaman_benchmark_data.json", [])
    if not benchmarks:
        return "–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."
    
    formatted = []
    for item in benchmarks:
        top_spends = ", ".join([f"{k} ({v:.0f} KZT)" for k, v in item.get("top_spending_categories", {}).items()])
        goals = ", ".join(item.get("common_goals", []))
        formatted.append(
            f"–°–ï–ì–ú–ï–ù–¢: {item['segment_name']} | "
            f"–°—Ä–µ–¥–Ω–∏–π –¥–æ—Ö–æ–¥: {item['avg_monthly_income_kzt']:.0f} KZT. "
            f"–¢–æ–ø-—Ç—Ä–∞—Ç—ã: {top_spends}. "
            f"–ò–ù–°–ê–ô–¢: {item['motivational_insight']}"
        )
    return "\n\n---\n\n".join(formatted)


def detect_emotional_state(message: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    stress_keywords = ["—Å—Ç—Ä–µ—Å—Å", "–ø–µ—Ä–µ–∂–∏–≤–∞—é", "–≤–æ–ª–Ω—É—é—Å—å", "—Ç—Ä–µ–≤–æ–∂–Ω–æ", "—É—Å—Ç–∞–ª", "–ø—Ä–æ–±–ª–µ–º"]
    if any(word in message.lower() for word in stress_keywords):
        return "stressed"
    return "neutral"


def get_wellness_advice() -> str:
    """–°–æ–≤–µ—Ç—ã –ø–æ wellness"""
    tips = [
        "üíö –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –º–µ–¥–∏—Ç–∞—Ü–∏—é: –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 'Insight Timer'.",
        "üö∂ –ü—Ä–æ–≥—É–ª–∫–∞ –≤ –ø–∞—Ä–∫–µ —Å–Ω–∏–∂–∞–µ—Ç —Å—Ç—Ä–µ—Å—Å –Ω–∞ 25%.",
        "üìù –í–µ–¥–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –¥–Ω–µ–≤–Ω–∏–∫–∞ —Å–Ω–∏–∂–∞–µ—Ç —Ç—Ä–µ–≤–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ 30%.",
        "‚òï –í—Å—Ç—Ä–µ—Ç—å—Ç–µ—Å—å —Å –¥—Ä—É–≥–æ–º –∑–∞ —á–∞—à–∫–æ–π —á–∞—è –¥–æ–º–∞.",
        "üßò –ü—Ä–∞–∫—Ç–∏–∫–∞ –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏: –∑–∞–ø–∏—Å—ã–≤–∞–π—Ç–µ 3 –≤–µ—â–∏, –∑–∞ –∫–æ—Ç–æ—Ä—ã–µ –±–ª–∞–≥–æ–¥–∞—Ä–Ω—ã.",
    ]
    return random.choice(tips)


STATIC_CLIENT_PROFILE = load_personalized_client_context()
BENCHMARK_DATA = load_benchmark_data()

print("üë§ –ü—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω." if "–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞" not in STATIC_CLIENT_PROFILE else "‚ö†Ô∏è –ü—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞ –ù–ï –∑–∞–≥—Ä—É–∂–µ–Ω.")
print("üìà –ë–µ–Ω—á–º–∞—Ä–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã." if "–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞" not in BENCHMARK_DATA else "‚ö†Ô∏è –ë–µ–Ω—á–º–∞—Ä–∫–∏ –ù–ï –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")


# ==================== PYDANTIC MODELS ====================

class ChatRequest(BaseModel):
    session_id: str
    message: str

class ChatResponse(BaseModel):
    role: str
    content: str

class AnalyzeRequest(BaseModel):
    session_id: str

class AnalyzeResponse(BaseModel):
    summary: str
    categories: Dict[str, float]


# ==================== –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ü–†–û–ö–°–ò ====================

async def proxy_request(
    method: str,
    path: str,
    body: Optional[Dict] = None,
    files: Optional[Dict] = None
) -> Dict:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API"""
    url = f"{BASE_URL}{path}"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    
    try:
        if method == "GET":
            response = await http_client.get(url, headers=headers)
        elif method == "POST":
            if files:
                response = await http_client.post(url, headers=headers, files=files, data=body)
            else:
                response = await http_client.post(url, headers=headers, json=body)
        elif method == "DELETE":
            response = await http_client.delete(url, headers=headers)
        else:
            raise HTTPException(status_code=405, detail="Method not allowed")
        
        response.raise_for_status()
        return response.json()
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=e.response.text)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== CHAT COMPLETIONS ====================

@app.post("/v1/chat/completions")
@app.post("/chat/completions")
@app.post("/engines/{model}/chat/completions")
@app.post("/openai/deployments/{model}/chat/completions")
async def chat_completions(request: Request, model: Optional[str] = None):
    """Chat Completion API"""
    body = await request.json()
    if model:
        body["model"] = model
    return await proxy_request("POST", "/v1/chat/completions", body)


# ==================== COMPLETIONS ====================

@app.post("/v1/completions")
@app.post("/completions")
@app.post("/engines/{model}/completions")
@app.post("/openai/deployments/{model}/completions")
async def completions(request: Request, model: Optional[str] = None):
    """Text Completion API"""
    body = await request.json()
    if model:
        body["model"] = model
    return await proxy_request("POST", "/v1/completions", body)


# ==================== EMBEDDINGS ====================

@app.post("/v1/embeddings")
@app.post("/embeddings")
@app.post("/engines/{model}/embeddings")
@app.post("/openai/deployments/{model}/embeddings")
async def embeddings(request: Request, model: Optional[str] = None):
    """Embeddings API"""
    body = await request.json()
    if model:
        body["model"] = model
    return await proxy_request("POST", "/v1/embeddings", body)


# ==================== IMAGES ====================

@app.post("/v1/images/generations")
@app.post("/images/generations")
async def image_generations(request: Request):
    """Image Generation API"""
    body = await request.json()
    return await proxy_request("POST", "/v1/images/generations", body)


@app.post("/v1/images/edits")
@app.post("/images/edits")
async def image_edits(
    image: UploadFile = File(...),
    prompt: str = Form(...),
    mask: Optional[UploadFile] = File(None)
):
    """Image Edit API"""
    files = {"image": image.file}
    if mask:
        files["mask"] = mask.file
    data = {"prompt": prompt}
    return await proxy_request("POST", "/v1/images/edits", data, files)


# ==================== AUDIO ====================

@app.post("/v1/audio/transcriptions")
@app.post("/audio/transcriptions")
async def audio_transcriptions(
    file: UploadFile = File(...),
    model: str = Form("whisper-1")
):
    """Audio Transcriptions API"""
    files = {"file": file.file}
    data = {"model": model}
    return await proxy_request("POST", "/v1/audio/transcriptions", data, files)


@app.post("/v1/audio/speech")
@app.post("/audio/speech")
async def audio_speech(request: Request):
    """Audio Speech (TTS) API"""
    body = await request.json()
    return await proxy_request("POST", "/v1/audio/speech", body)


# ==================== MODERATIONS ====================

@app.post("/v1/moderations")
@app.post("/moderations")
async def moderations(request: Request):
    """Moderations API"""
    body = await request.json()
    return await proxy_request("POST", "/v1/moderations", body)


# ==================== FILES ====================

@app.post("/v1/files")
@app.post("/files")
async def create_file(file: UploadFile = File(...), purpose: str = Form(...)):
    """Create File"""
    files = {"file": file.file}
    data = {"purpose": purpose}
    return await proxy_request("POST", "/v1/files", data, files)


@app.get("/v1/files")
@app.get("/files")
async def list_files():
    """List Files"""
    return await proxy_request("GET", "/v1/files")


@app.get("/v1/files/{file_id}")
@app.get("/files/{file_id}")
async def get_file(file_id: str):
    """Get File"""
    return await proxy_request("GET", f"/v1/files/{file_id}")


@app.delete("/v1/files/{file_id}")
@app.delete("/files/{file_id}")
async def delete_file(file_id: str):
    """Delete File"""
    return await proxy_request("DELETE", f"/v1/files/{file_id}")


@app.get("/v1/files/{file_id}/content")
@app.get("/files/{file_id}/content")
async def get_file_content(file_id: str):
    """Get File Content"""
    return await proxy_request("GET", f"/v1/files/{file_id}/content")


# ==================== BATCHES ====================

@app.post("/v1/batches")
@app.post("/batches")
async def create_batch(request: Request):
    """Create Batch"""
    body = await request.json()
    return await proxy_request("POST", "/v1/batches", body)


@app.get("/v1/batches")
@app.get("/batches")
async def list_batches():
    """List Batches"""
    return await proxy_request("GET", "/v1/batches")


@app.get("/v1/batches/{batch_id}")
@app.get("/batches/{batch_id}")
async def retrieve_batch(batch_id: str):
    """Retrieve Batch"""
    return await proxy_request("GET", f"/v1/batches/{batch_id}")


# ==================== FINE-TUNING ====================

@app.post("/v1/fine_tuning/jobs")
@app.post("/fine_tuning/jobs")
async def create_fine_tuning_job(request: Request):
    """Create Fine-Tuning Job (Enterprise)"""
    body = await request.json()
    return await proxy_request("POST", "/v1/fine_tuning/jobs", body)


@app.get("/v1/fine_tuning/jobs")
@app.get("/fine_tuning/jobs")
async def list_fine_tuning_jobs():
    """List Fine-Tuning Jobs (Enterprise)"""
    return await proxy_request("GET", "/v1/fine_tuning/jobs")


@app.post("/v1/fine_tuning/jobs/{job_id}/cancel")
@app.post("/fine_tuning/jobs/{job_id}/cancel")
async def cancel_fine_tuning_job(job_id: str):
    """Cancel Fine-Tuning Job (Enterprise)"""
    return await proxy_request("POST", f"/v1/fine_tuning/jobs/{job_id}/cancel")


# ==================== ASSISTANTS ====================

@app.get("/v1/assistants")
@app.get("/assistants")
async def get_assistants():
    """Get Assistants"""
    return await proxy_request("GET", "/v1/assistants")


@app.post("/v1/assistants")
@app.post("/assistants")
async def create_assistant(request: Request):
    """Create Assistant"""
    body = await request.json()
    return await proxy_request("POST", "/v1/assistants", body)


@app.delete("/v1/assistants/{assistant_id}")
@app.delete("/assistants/{assistant_id}")
async def delete_assistant(assistant_id: str):
    """Delete Assistant"""
    return await proxy_request("DELETE", f"/v1/assistants/{assistant_id}")


# ==================== THREADS ====================

@app.post("/v1/threads")
@app.post("/threads")
async def create_thread(request: Request):
    """Create Thread"""
    body = await request.json()
    return await proxy_request("POST", "/v1/threads", body)


@app.get("/v1/threads/{thread_id}")
@app.get("/threads/{thread_id}")
async def get_thread(thread_id: str):
    """Get Thread"""
    return await proxy_request("GET", f"/v1/threads/{thread_id}")


@app.post("/v1/threads/{thread_id}/messages")
@app.post("/threads/{thread_id}/messages")
async def add_messages(thread_id: str, request: Request):
    """Add Messages to Thread"""
    body = await request.json()
    return await proxy_request("POST", f"/v1/threads/{thread_id}/messages", body)


@app.get("/v1/threads/{thread_id}/messages")
@app.get("/threads/{thread_id}/messages")
async def get_messages(thread_id: str):
    """Get Messages from Thread"""
    return await proxy_request("GET", f"/v1/threads/{thread_id}/messages")


@app.post("/v1/threads/{thread_id}/runs")
@app.post("/threads/{thread_id}/runs")
async def run_thread(thread_id: str, request: Request):
    """Run Thread"""
    body = await request.json()
    return await proxy_request("POST", f"/v1/threads/{thread_id}/runs", body)


# ==================== RERANK ====================

@app.post("/v1/rerank")
@app.post("/v2/rerank")
@app.post("/rerank")
async def rerank(request: Request):
    """Rerank API"""
    body = await request.json()
    return await proxy_request("POST", "/v1/rerank", body)


# ==================== VECTOR STORES ====================

@app.post("/v1/vector_stores")
@app.post("/vector_stores")
async def create_vector_store(request: Request):
    """Create Vector Store"""
    body = await request.json()
    return await proxy_request("POST", "/v1/vector_stores", body)


@app.post("/v1/vector_stores/{vector_store_id}/search")
@app.post("/vector_stores/{vector_store_id}/search")
async def search_vector_store(vector_store_id: str, request: Request):
    """Search Vector Store"""
    body = await request.json()
    return await proxy_request("POST", f"/v1/vector_stores/{vector_store_id}/search", body)


# ==================== UTILS ====================

@app.post("/utils/token_counter")
async def token_counter(request: Request):
    """Token Counter Utility"""
    body = await request.json()
    return await proxy_request("POST", "/utils/token_counter", body)


@app.post("/utils/transform_request")
async def transform_request(request: Request):
    """Transform Request Utility"""
    body = await request.json()
    return await proxy_request("POST", "/utils/transform_request", body)


# ==================== WEBSOCKET ====================

@app.websocket("/v1/realtime")
@app.websocket("/realtime")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket –¥–ª—è realtime –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏"""
    await websocket.accept()
    try:
        while True:
            data = await websocket.receive_text()
            await websocket.send_text(f"Echo: {data}")
    except Exception as e:
        print(f"WebSocket error: {e}")


# ==================== ZAMAN BANK CUSTOM ENDPOINTS ====================

async def get_embedding(text: str) -> List[float]:
    """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥"""
    try:
        response = await http_client.post(
            f"{BASE_URL}/v1/embeddings",
            headers={"Authorization": f"Bearer {API_KEY}"},
            json={"input": [text], "model": EMBEDDING_MODEL}
        )
        response.raise_for_status()
        return response.json()['data'][0]['embedding']
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        return []


def query_vector_db(embedding: List[float]) -> str:
    """–ò—â–µ—Ç –≤ ChromaDB"""
    if not collection or not embedding:
        return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."
    results = collection.query(query_embeddings=[embedding], n_results=3)
    return "\n---\n".join(results['documents'][0])


async def get_llm_response(session_id: str, user_message: str) -> str:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LLM —Å RAG"""
    user_context = USER_STATE_CACHE.get(session_id, {}).get(
        "summary", 
        "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –ø—Ä–æ–≤–µ–¥–µ–Ω."
    )
    
    emotional_state = detect_emotional_state(user_message)
    wellness_tip = ""
    if emotional_state == "stressed":
        wellness_tip = f"\n\n**üåø –°–æ–≤–µ—Ç:**\n{get_wellness_advice()}"
    
    query_embedding = await get_embedding(f"{user_message}. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {user_context}")
    retrieved_docs = query_vector_db(query_embedding)
    
    MASTER_PROMPT = f"""
–¢—ã ‚Äî Zaman, –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏—Å–ª–∞–º—Å–∫–æ–≥–æ –±–∞–Ω–∫–∞.

–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π Bold –∏–ª–∏ Italic –≤ –æ—Ç–≤–µ—Ç–∞—Ö.

–ö–û–ù–¢–ï–ö–°–¢ –ö–õ–ò–ï–ù–¢–ê:
{user_context}

–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê:
{BENCHMARK_DATA}

–ë–ê–ó–ê –ó–ù–ê–ù–ò–ô:
{retrieved_docs}

–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–û–ï –°–û–°–¢–û–Ø–ù–ò–ï: {emotional_state}

–û—Ç–≤–µ—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞, —É—á–∏—Ç—ã–≤–∞—è –µ–≥–æ —Å–∏—Ç—É–∞—Ü–∏—é –∏ –ø—Ä–æ–¥—É–∫—Ç—ã –±–∞–Ω–∫–∞.
"""
    
    try:
        response = await http_client.post(
            f"{BASE_URL}/v1/chat/completions",
            headers={"Authorization": f"Bearer {API_KEY}"},
            json={
                "model": LLM_MODEL,
                "messages": [
                    {"role": "system", "content": MASTER_PROMPT},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.8,
                "max_tokens": 600
            }
        )
        response.raise_for_status()
        ai_response = response.json()['choices'][0]['message']['content']
        return ai_response + wellness_tip
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ LLM: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


def analyze_mock_transactions() -> AnalyzeResponse:
    """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"""
    transactions = load_json_safe("../data/mock_transactions.json", [])
    if not transactions:
        return AnalyzeResponse(summary="–û—à–∏–±–∫–∞: —Ñ–∞–π–ª —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω.", categories={})
    
    categories: Dict[str, float] = {}
    total_income = 0
    total_expense = 0
    
    for tx in transactions:
        amount = tx["amount"]
        category = tx["category"]
        if amount > 0:
            total_income += amount
        else:
            categories[category] = categories.get(category, 0) + abs(amount)
            total_expense += abs(amount)
    
    sorted_categories = dict(sorted(categories.items(), key=lambda x: x[1], reverse=True))
    
    dynamic_summary = (
        f"–ö–ª–∏–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª {total_income:.0f} KZT –¥–æ—Ö–æ–¥–∞ –∏ –ø–æ—Ç—Ä–∞—Ç–∏–ª {total_expense:.0f} KZT. "
        f"–û—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–∞—Ç—ã: " + ", ".join([f"{k} ({v:.0f} KZT)" for k, v in list(sorted_categories.items())[:3]])
    )
    
    full_context = f"–°–¢–ê–¢–ò–ß–ï–°–ö–ò–ô –ü–†–û–§–ò–õ–¨: {STATIC_CLIENT_PROFILE}\n\n–î–ò–ù–ê–ú–ò–ö–ê: {dynamic_summary}"
    
    return AnalyzeResponse(summary=full_context, categories=sorted_categories)


# ==================== –§–†–û–ù–¢–ï–ù–î ====================

@app.get("/", include_in_schema=False)
def serve_main_frontend():
    if not os.path.exists(INDEX_HTML_PATH):
        raise HTTPException(status_code=404, detail="index.html –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return FileResponse(INDEX_HTML_PATH, media_type="text/html")


@app.get("/chat", include_in_schema=False)
def serve_chat_frontend():
    if not os.path.exists(CHAT_HTML_PATH):
        raise HTTPException(status_code=404, detail="chat.html –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return FileResponse(CHAT_HTML_PATH, media_type="text/html")


@app.post("/api/analyze", response_model=AnalyzeResponse)
async def analyze_transactions_endpoint(request: AnalyzeRequest):
    response = analyze_mock_transactions()
    if request.session_id not in USER_STATE_CACHE:
        USER_STATE_CACHE[request.session_id] = {}
    USER_STATE_CACHE[request.session_id]["summary"] = response.summary
    return response


@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_assistant(request: ChatRequest):
    if not collection:
        raise HTTPException(status_code=500, detail="–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    ai_response = await get_llm_response(request.session_id, request.message)
    return ChatResponse(role="assistant", content=ai_response)


# ==================== –ó–ê–ü–£–°–ö ====================

if __name__ == "__main__":
    SERVER_URL = "http://localhost:8000"
    
    def start_server():
        uvicorn.run(app, host="0.0.0.0", port=8000)
    
    print(f"‚úÖ Zaman AI —Å –ø–æ–ª–Ω—ã–º API —Ä–æ—É—Ç–µ—Ä–æ–º –∑–∞–ø—É—â–µ–Ω: {SERVER_URL}")
    print(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API: {SERVER_URL}/docs")
    print(f"üåê –û—Ç–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä...")
    
    threading.Timer(1.5, lambda: webbrowser.open(SERVER_URL)).start()
    start_server()